{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import hyperspy.api as hs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from hyperspy.misc.machine_learning import import_sklearn\n",
    "import importlib\n",
    "from alt_nonneg_least_squares import *\n",
    "from implementations import *\n",
    "from clustering_VCA import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data From Hyperspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EDS data using hyperspy\n",
    "s = hs.load(\"1 selection.bcf\")[-1]\n",
    "# cut out the \"zero peak\" of EDS data\n",
    "for i in range(58):\n",
    "    s.isig[i] = 0\n",
    "\n",
    "# Take a patch of 100*100 to perform the decomposition.\n",
    "s_temp = hs.signals.EDSTEMSpectrum(s.data[100:200,100:200,:])\n",
    "s_temp.change_dtype('float')\n",
    "\n",
    "# Perform the decomposition\n",
    "s_temp.decomposition(algorithm=\"nmf\",output_dimension=2)\n",
    "loadings_hyperspy = s_temp.get_decomposition_loadings().data\n",
    "factors_hyperspy = s_temp.get_decomposition_factors().data\n",
    "plot( factors_hyperspy, \"nmf_hyperspy.png\" , \"Decomposition using Hyperspy\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the heuristic for Phase B and append."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = s_temp.data\n",
    "bkg = get_Component_B( data, loadings_hyperspy )\n",
    "data, loadings, factors, bkg = reshape( data, loadings_hyperspy, factors_hyperspy, bkg )\n",
    "data, loadings, factors = append_Component_B( data, loadings, factors, bkg )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Alternating Non negative Least Square Algorithm and save the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the W,H randomly\n",
    "m = data.shape[0]\n",
    "n = data.shape[1]\n",
    "k = 2\n",
    "\n",
    "W = np.zeros((m,k))\n",
    "H = np.zeros((k,n))\n",
    "\n",
    "for i in range(m):\n",
    "\tfor j in range(k):\n",
    "\t\tW[i,j] = np.random.uniform(0,1)\n",
    "\n",
    "for i in range(k):\n",
    "\tfor j in range(n):\n",
    "\t\tH[i,j] = np.random.uniform(0,1)\n",
    "\n",
    "# Intialize using ALS for better convergence. \n",
    "# Using the heuristic which is present in data[0,:] after the decomposition.\n",
    "W,H = ALS( data, W, H, 10, data[0,:] )\n",
    "# Decompose using ALternate Least Square with parameter\n",
    "# The parameters are obtained after tuning using the below function.\n",
    "best_lambda_si,best_lambda_bkg,best_gamma = tune_hyper_parameters(data)\n",
    "W,H = ANLS( data, W, H,20,1,0.01,0.01,10 )\n",
    "print_loss(data,W,H)\n",
    "plot( H, \"nmf_anls.png\" , \"Decomposition using ANLS NMF\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EDS data for hyperspy again for the experiment below\n",
    "s = hs.load(\"1 selection.bcf\")[-1]\n",
    "for i in range(58):\n",
    "    s.isig[i] = 0\n",
    "\n",
    "# Take a patch of 100*100 to perform the decomposition.\n",
    "s_temp = hs.signals.EDSTEMSpectrum(s.data[100:200,100:200,:])\n",
    "s_temp.change_dtype('float')\n",
    "\n",
    "data = s_temp.data\n",
    "data = data.reshape(100*100,2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition using Vertex Component Analysis\n",
    "# This saves the resultant decomposition in VCA.png in the current folder\n",
    "VCA( data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition using Kmeans Clustering\n",
    "# This saves the resultant decomposition in kmeans.png in the current folder\n",
    "K_means( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition using Fuzzy Clustering\n",
    "# This saves the resultant decomposition in fuzzy.png in the current folder\n",
    "fuzzy_clustering( data )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
